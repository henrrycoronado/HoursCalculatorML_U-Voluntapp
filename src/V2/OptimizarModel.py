import pandas as pd
import xgboost as xgb
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np
import os

# ==========================================
# 1. CARGA DE DATOS
# ==========================================
ARCHIVO_DATASET = '../data/V2/dataset_voluntariado_aumentado.csv'

print(f"--- Cargando dataset para optimizaci√≥n: {ARCHIVO_DATASET} ---")
if not os.path.exists(ARCHIVO_DATASET):
    raise FileNotFoundError(f"‚ùå No encuentro el archivo {ARCHIVO_DATASET}. Aseg√∫rate de que est√© en esta carpeta.")

df = pd.read_csv(ARCHIVO_DATASET)

# Definimos variables (Igual que antes)
X = df[[
    'X1_Horas_Actuales', 'X2_Frec_Semanal', 'X3_Horas_Fallidas', 
    'X4_Semanas_Restantes', 'X5_Disp_Neta_Restante', 'X6_Antiguedad', 
    'X7_Tipo_Carrera', 'X8_Beca', 'X9_Carrera_Id'
]]
Y = df['Y_Horas_Totales_Finales']

# Split (mantenemos la misma semilla 42 para comparar manzanas con manzanas)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# ==========================================
# 2. DEFINIR LA REJILLA DE B√öSQUEDA
# ==========================================
# El modelo probar√° TODAS estas combinaciones (4 x 4 x 4 x 2 x 2 = 256 modelos distintos)
param_grid = {
    'n_estimators': [100, 200, 300, 500],      # N√∫mero de √°rboles
    'max_depth': [3, 4, 5, 6],                 # Profundidad (Complejidad)
    'learning_rate': [0.01, 0.05, 0.1, 0.2],   # Velocidad de aprendizaje
    'subsample': [0.8, 1.0],                   # % de filas usadas por √°rbol
    'colsample_bytree': [0.8, 1.0]             # % de columnas usadas por √°rbol
}

xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)

print("\n--- üê¢ Iniciando B√∫squeda Intensiva (Grid Search) ---")
print("Esto puede tardar unos minutos dependiendo de tu PC...")

# Configuraci√≥n de la b√∫squeda
grid_search = GridSearchCV(
    estimator=xgb_model, 
    param_grid=param_grid, 
    scoring='r2', 
    cv=3,           # Validaci√≥n cruzada de 3 pliegues (triple verificaci√≥n)
    verbose=1, 
    n_jobs=-1       # Usar todos los n√∫cleos del CPU
)

grid_search.fit(X_train, Y_train)

# ==========================================
# 3. RESULTADOS Y GUARDADO
# ==========================================
print("\n=============================================")
print("üèÜ ¬°OPTIMIZACI√ìN COMPLETADA!")
print("=============================================")
print(f"Mejor combinaci√≥n encontrada: {grid_search.best_params_}")

best_model = grid_search.best_estimator_
Y_pred = best_model.predict(X_test)

# M√©tricas del modelo ganador
new_r2 = r2_score(Y_test, Y_pred)
new_rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))

print(f"\nüìä RESULTADOS DEL MEJOR MODELO:")
print(f"Nuevo R2: {new_r2:.4f}")
print(f"Nuevo RMSE: ¬±{new_rmse:.2f} Horas")

# Comparativa r√°pida
print(f"\nComparativa vs Anterior (0.6345):")
if new_r2 > 0.6345:
    diff = (new_r2 - 0.6345) * 100
    print(f"‚úÖ MEJORA DETECTADA: +{diff:.2f}% de precisi√≥n explicada.")
    
    # Guardar el modelo ganador
    if not os.path.exists('model_assets'):
        os.makedirs('model_assets')
    
    best_model.save_model('model_assets/modelo_voluntariado_xgb_optimizado.json')
    print("üíæ Modelo optimizado guardado en 'model_assets/modelo_voluntariado_xgb_optimizado.json'")
else:
    print("‚ö†Ô∏è El modelo no mejor√≥ significativamente. Los datos tienen mucho ruido natural.")